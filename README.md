# Natural-Language-Processing-for-sentiment-analysis
Tweets are automatically judged as positive or negative. To train a model to do so, more than a million (1,048,572) labeled tweets are used from the "Sentiment Analysis Dataset" on Kaggle (https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset). The tweets are assigned with numerical values using Keras tokenizer and then are (zero-) padded to equalize their lengths to be of size 46 (the number of words in the longest tweet) . The total number of words from the tweets that are used in the model are limited to 10k (to prevent overfitting). This numerical representation is then further transformed using an embedding layer within the model, where each word is assigned with a 10 dimensional vector. Eventually, each tweet is represented by a 46x10 matrix. The model includes LSTM (long short-term memory) layers, dense layers, a binary cross entropy loss function and the accuracy metric. The model achieve accuracy of 0.82 both in training and validation. Finally, the model is evaluated by plotting a confusion matrix and by judging a few "unseen" tweets.
